{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Trabajo Práctico 2"
      ],
      "metadata": {
        "id": "ne20ys4gWagd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consigna\n",
        "\n",
        "En este práctico se trabajará con el dataset de Rossmann. Rossmann es una cadena de drugstores con más de 3000 tiendas en 7 países de Europa. La tarea que se intentará resolver con este dataset es el de predicción de las ventas totales de cada tienda que tendrán lugar en un intervalo de 6 semanas. Esta competencia fue presentada en Kaggle y se puede acceder a sus recursos relacionados:\n",
        "\n",
        "https://www.kaggle.com/c/rossmann-store-sales\n",
        "\n",
        "Este práctico consiste en generar un modelo que realice la inferencia para el problema planteado. Los entregables consisten en:\n",
        "\n",
        "Compartir el link de un repositorio que contenga:\n",
        "\n",
        "- La/s notebook/s con la resolución del ejercicio y todo el código propio utilizado para correr la/s notebooks.\n",
        "- Un archivo requirements.txt con las versiones de las librerías de Python utilizadas (en formato pip)\n",
        "- Captura de pantalla con el máximo score obtenido al hacer el late submission y el submission.csv utilizado.\n",
        "\n",
        "Además, la notebook principal debe incluir lo siguiente:\n",
        "\n",
        "- Una explicación detallada de cómo se preprocesaron los datos (aquellos provistos para la competencia y datos externos)\n",
        "- Una tabla con los distintos modelos e hiperparámetros que se hayan probado y sus respectivos scores.\n",
        "- Gráficos con los embeddings obtenidos.\n",
        "- Las respuestas a las siguientes preguntas:\n",
        "  - ¿Qué son los Entity Embeddings y cómo se relacionan con las variables categóricas?\n",
        "  - Explique la métrica utilizada en la competencia."
      ],
      "metadata": {
        "id": "xU_HNlEkWXYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets\n",
        "\n",
        "Los datos utilizados fueron los provistos para la competencia (train, test y store) y los externos utilizados por los que ganaron el 3er puesto de la competencia.\n"
      ],
      "metadata": {
        "id": "It-XfmsViU1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasets provistos por la competencia\n",
        "\n",
        "$\\textbf{Kaggle Challenge de Rossmann Store Sales}$\n",
        "\n",
        "https://www.kaggle.com/competitions/rossmann-store-sales/overview\n",
        "\n",
        "\n",
        "$\\textbf{Files:}$\n",
        "* train.csv - historical data including Sales\n",
        "* test.csv - historical data excluding Sales\n",
        "* sample_submission.csv - a sample submission file in the correct format\n",
        "* store.csv - supplemental information about the stores\n",
        "\n",
        "\n",
        "$\\textbf{Data fields:}$\n",
        "Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
        "\n",
        "* Id - an Id that represents a (Store, Date) duple within the test set\n",
        "* Store - a unique Id for each store\n",
        "* Sales - the turnover for any given day (this is what you are predicting)\n",
        "* Customers - the number of customers on a given day\n",
        "* Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
        "* StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
        "* SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
        "* StoreType - differentiates between 4 different store models: a, b, c, d\n",
        "Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
        "* CompetitionDistance - distance in meters to the nearest competitor store\n",
        "* CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
        "* Promo - indicates whether a store is running a promo on that day\n",
        "* Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
        "Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
        "* PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store\n"
      ],
      "metadata": {
        "id": "Aj7GojvieH0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasets externos\n",
        "\n",
        "Los datasets externos utilizados fueron los siguientes:\n",
        "\n",
        "* store_states.csv - indica el estado en el que se encuentra cada una de las tiendas\n",
        "* state_names.csv - indica el acrónimo de cada estado\n",
        "* googletrend.csv - indica las tendencias por semana\n",
        "* wheather.csv - indica las condiciones meteorológicas por día"
      ],
      "metadata": {
        "id": "ZsN1LEB--Mwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento de datos\n",
        "\n",
        "Los datos utilizados se preprocesan el los notebooks '02-data-preprocess.ipynb', '03-durations-preprocess.ipynb' y '04-Normalize-and_encode.ipynb'."
      ],
      "metadata": {
        "id": "h2C6MrknX-h3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\textbf{En el Notebook '02-data-preprocess.ipynb':}$\n",
        "\n",
        "El preprocesamiento se inició revisando los datasets en busca de datos faltantes. Se encontraron datos faltantes en variables de los datasets test, store y weather, y estos fueron tratados de distintas formas:\n",
        "* En test, los datos faltantes de la variable 'Open' se reemplazaron por 1 (abierto) a menos de que fuese día 7 (domingo) ya que usualmente las tiendas se encuentran cerradas.\n",
        "* En store, los datos faltantes de las variables 'CompetitionOpenSinceMonth' y 'CompetitionOpenSinceYear' (o los anteriores al año 1990) fueron reemplazados por el mes 1 (enero) de 1990.\n",
        "* En store, los datos faltantes de la variable 'CompetitionDistance' se consideraron como lejanos y fueron reemplazados por el valor máximo de la variable (75860).\n",
        "* En store, los datos faltantes de las variables 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval' que no tenian Promo2 fueron reemplazados por la primera semana de 1990 y duración nula (-)\n",
        "* En weather, los datos faltantes de las variables 'Max_VisibilityKm', 'Mean_VisibilityKm', 'Min_VisibilitykM', 'Max_Gust_SpeedKm_h', 'CloudCover' y 'Events' fueron reemplazados por condiciones climáticas tranquilas, utilizando los máximos y mínimos de estas variables.\n",
        "\n",
        "Luego, en el dataset store se crearon nuevas columnas con las fechas en formato año-mes-día para minimizar el número de variables.\n",
        "En el dataset googletrend, se creó una variable con el acrónimo del estado en el que se encuentra la tienda a partir de un split de la variable 'File' del mismo.\n",
        "\n",
        "Después, se unieron los datasets para obtener un nuevo train y test, juntandolos en el siguiente orden:\n",
        "* weather y state_names en weather\n",
        "* store y store_states en store\n",
        "* train y states en joined_train\n",
        "* test y states en joined_test\n",
        "* joined_train y googletrend en joined_train\n",
        "* joined_test y googletrend en joined_test\n",
        "* joined_train y weather en joined_train\n",
        "* joined_test y weather en joined_test\n",
        "\n",
        "Para continuar se agregaron 2 columnas llamadas 'CompetitionDaysOpen' y 'Promo2Days' obtenidas a partir de las variables 'CompetitionOpenSinceMonth' y 'CompetitionOpenSinceYear', y 'Promo2SinceWeek' y 'Promo2SinceYear', respectivamente. Estas nuevas variables se corrigieron para estar en meses, no tener valores negativos y tener un máximo de 24 meses (2 años).\n",
        "\n",
        "Por último se eliminan los datos duplicados, y se almacenan los nuevos datasets train y test en archivos .fth.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7d4b68btclDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\textbf{En el Notebook '03-durations-preprocess.ipynb':}$\n",
        "\n",
        "Acá se generaron nuevas columnas del tiempo before (antes) y after (después) de eventos (StateHoliday, SchoolHoliday, Promo). Luego se eliminaron los datos NaT (Not a Time), y se suavizaron las columnas de valores temporales. Por úlimo, se almacenaron una vez más los datasets train y test en archivos .fth.\n",
        "\n"
      ],
      "metadata": {
        "id": "XfO10WZyzkTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\textbf{En el Notebook '04-Normalize-and_encode.ipynb':}$\n",
        "\n",
        "Aquí se separan las variables en categóricas y continuas. Las variables categóricas se codificaron usando la función LabelEncoder, y las continuas se estandarizaron usando la función StandardScaler, ambas de la librería sklearn.\n",
        "\n",
        "También se eliminaron los datos en los que las ventas eran nulas. Finalmente, se almacenaron nuevamente los datasets train y test en archivos .fth.\n",
        "\n"
      ],
      "metadata": {
        "id": "wXP4tYEzvqvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos e hiperparámetros\n",
        "\n",
        "Se 'submitearon' varios modelos generados en las notebooks '06-full-model.ipynb', '07-lightGBM.ipynb', '08-XGBoost.ipynb' y '09-lightGBM-hyp-search.ipynb'. En la siguiente tabla se muestran los modelos enviados, algunos de sus parámetros y el score que se obtuvo."
      ],
      "metadata": {
        "id": "5bvQ1YHl2U-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Notebook | Modelo | Learning rate | Epochs | Batch size | Min child Samples | Score |\n",
        "|--------|--------|---------------|--------|------------|-------------------|-------|\n",
        "|06-full-model|Red neuronal con embeddings |0.001|20|256|-|0.25305|\n",
        "|08-XGBoost|XGBRegressor             |0.25 |-|-|-|0.22672|\n",
        "|09-lightGBM-hyp-search|LGBMRegressor con Hyp Search|0.05|-|-|5|0.13695|\n",
        "|07-lightGBM|LGBMRegressor           |0.05 |-|-|5|0.13564|\n"
      ],
      "metadata": {
        "id": "euFkvbDo3R7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\textbf{Mejor score obtenido}$:\n",
        "\n",
        "En la siguiente figura se muestra la captura de pantalla del mejor score obtenido, generado con el modelo LGBMRegressor ubicado en la notebook '07-lightGBM.ipynb'."
      ],
      "metadata": {
        "id": "60V8egq1g8nQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1bxgmfn_Ae2FUulGeynmU1dD50qiGkQiw)\n"
      ],
      "metadata": {
        "id": "k3-iETM3gwmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings\n",
        "\n",
        "Los embeddings obtenidos fueron los de las variables 'DayOfWeek' y 'Store'."
      ],
      "metadata": {
        "id": "FUgtgaPQ84f_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los embeddings de la variable 'DayOfWeek' se muestran en la siguiente figura:"
      ],
      "metadata": {
        "id": "zQuL4v-9DwcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1JBrU80gSlbqSpPUhzjXSZ9m07YKA1irk)"
      ],
      "metadata": {
        "id": "vSyILFrXD4PA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la imagen anterior se puede notar que los días entre semana (Monday-Friday) se encuentran más cercanos entre sí, y los días de fin de semana (Saturday y Sunday) lejos de los anteriores, lo cual hace sentido en cuanto al comportamiento de las ventas en general. En particular, se puede notar una alta proximidad entre los días Wednesday y Thursday."
      ],
      "metadata": {
        "id": "X5RQ7WtJEpDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los embeddings de la variable 'Store' se muestran en la siguiente figura:"
      ],
      "metadata": {
        "id": "GXhEPOx2ECja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1GmVZWMeAaXi5UIRVXSEW8Sr6CXmH1-j-)"
      ],
      "metadata": {
        "id": "vL9G-4izBLfF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta imagen se puede ver que las tiendas forman un cluster, y que las tiendas 84, 787 y sobre todo la 816 son las más aisladas."
      ],
      "metadata": {
        "id": "fRtQg0t8Fbhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preguntas"
      ],
      "metadata": {
        "id": "zYfQXfDU87lY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ¿Qué son los Entity Embeddings y cómo se relacionan con las variables categóricas?\n",
        "\n",
        "En esencia, los entity embeddings son vectores que representan algo, una entidad. Las variables categóricas pueden ser representadas de forma compacta y continua mediante el mapeo realizado mediante entity embedding.\n",
        "\n",
        "De esta forma, se puede pasar de variables categóricas a continuas, siendo estas de preferencia a la hora de aplicar redes neuronales. Los valores de una variable categórica siempre tienen algún tipo de relación intrínseca. Otra alternativa para aplicar redes neuronales a problemas con variables categóricas es one-hot-encoding, pero este método ignora las relaciones entre los valores de una variable. Por el contrario, entity embedding revela las propiedades intrínsecas de las variables categóricas mediante el mapeo cercano de valores similares. Además, entity embedding reduce el uso de memoria y acelera la performance de las redes neuronales.\n"
      ],
      "metadata": {
        "id": "eMrJtIiY9JwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explique la métrica utilizada en la competencia\n",
        "\n",
        "La métrica utilizada en esta competencia es la raíz cuadrada del error cuadrático medio porcentual (RMSPE). El mismo se calcula de la siguiente forma:\n",
        "\n",
        "$RMSPE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}(\\frac{y_i - \\hat{y_i}}{y_i})^2}$\n",
        "\n",
        "A partir de la fórmula vemos que el RMSPE realiza una suma de los errores de todos los datos. Este error tiene en cuenta la diferencia entre los valor predichos y los reales. Se utiliza el valor cuadrático, por lo que se ignora el signo de estas diferencias. A su vez, se divide por el valor real para obtenerlo en forma de porcentaje, lo que hace que el tamaño de este error no dependa del orden de magnitud de la variable y. Por esto, el RMSPE resulta una métrica bastante objetiva y apropiada para esta competencia.\n",
        "\n"
      ],
      "metadata": {
        "id": "88NkWK4E9L0J"
      }
    }
  ]
}